{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回帰の場合、分割後の標準偏差の総和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation(y):\n",
    "    d = y - y.mean()\n",
    "    s = s ** 2\n",
    "    return np.sqrt(s.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類の場合、ジニ不純物\n",
    "どれぐらい単一のクラスから成っているかを評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割後のデータ数を総和として、データ毎にそのデータが誤ってラベル付けされる確率に、そのクラスがリスト内に存在する割合を重みとして掛けたもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Gini(p) = \\sum_{i=1}^{n}p_i(1-p_i)=1-\\sum_{i=1}^{n}p_i^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def gini(y):\n",
    "    i = y.argmax(axis=1) # one-hot-vectorを仮定\n",
    "    clz = set(i)\n",
    "    c = Counter(i)\n",
    "    size = y.shape[0]\n",
    "    score = 0.0\n",
    "    for val in clz:\n",
    "        score += (c[val] / size) ** 2\n",
    "    return 1 - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gini(y):\n",
    "#    m = y.sum(axis=0)\n",
    "#    size = y.shape[0]\n",
    "#    e = [(p / size) for p in m]\n",
    "#    return 1 - np.sum(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain(情報利得)\n",
    "クラス分類で使用されるもう一つのMetric関数。情報理論に基づく関数で、分割後の目的変数に含まれる情報量が少なくなるように分割点を求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "親ノードから与えられたデータのエントロピーから子ノードに渡すデータのエントロピーの合計を引いたもの。\n",
    "Information gainはノード内の条件式が持つ情報量を最大化するようにデータを分割するMetric関数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Entropy(p) = -\\sum_{i=1}^{n}p_ilog_2(p_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infomation_gain(y):\n",
    "    i = y.argmax(axis=0)\n",
    "    clz = set(i)\n",
    "    c = Counter(i)\n",
    "    size = y.shape[0]\n",
    "    score = 0.0\n",
    "    for val in clz:\n",
    "        p= c[val] / size\n",
    "        if p != 0:\n",
    "            score += p * log2(p)\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionStump(深さ１の二分木)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純な分割機能として評価にしばしば使われる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import support\n",
    "from zeror import ZeroRule\n",
    "from linear import Linear\n",
    "\n",
    "class DecisionStump:\n",
    "    def __init__(self, metric=gini, leafModel=ZeroRule):\n",
    "        # 分割ルール\n",
    "        self.metric = metric\n",
    "        \n",
    "        # 葉のモデル\n",
    "        self.leafModel = leafModel\n",
    "    \n",
    "        # 左右の葉のモデルのインスタンス\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        # 分割に使用する目的変数の次元の位置と値\n",
    "        self.feat_index = 0\n",
    "        self.feat_val = np.nan\n",
    "        \n",
    "        # 分割評価スコア\n",
    "        self.score = np.nan\n",
    "    \n",
    "    def make_split(self, feat, val):\n",
    "        # 説明変数から取得したある1次元の配列を、特定の値で大小に分割する\n",
    "        left, right = [], []\n",
    "        for i, v in enumerate(feat):\n",
    "            if v < val:\n",
    "                left.append(i)\n",
    "            else:\n",
    "                right.append(i)\n",
    "        return left, right\n",
    "    \n",
    "    def make_loss(self, y1, y2, l, r):\n",
    "        # 分割後のスコアを計算\n",
    "        # y1, y2 : 分割した目的変数\n",
    "        # l , r  : 分割後の目的変数内のそれぞれのインデックス\n",
    "        # 出力は metric値＊重み\n",
    "        if y1.shape[0] == 0 or y2.shape[0] == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        total = y1.shape[0] + y2.shape[0]\n",
    "        \n",
    "        m1 = self.metric(y1) * (y1.shape[0] / total)\n",
    "        m2 = self.metirc(y2) * (y2.shape[0] / total)\n",
    "        return m1 + m2\n",
    "    \n",
    "    def make_tree(self, x, y):\n",
    "        # 説明変数と目的変数からデータを左右の枝に振り分ける\n",
    "        # 説明変数内のすべての次元に対して、その中の値でデータを分割した際のスコアを計算する\n",
    "        # スコアが最も小さくなる説明変数内の次元の位置と分割値をself.feat_indexとself.feat_valに格納\n",
    "        # 次元ｘデータ数のループで総当りする\n",
    "        self.feat_index = 0\n",
    "        self.feat_val = np.inf\n",
    "        score = np.inf\n",
    "        \n",
    "        # 左右のインデックス\n",
    "        left, right = list(range(x.shape[0])), []\n",
    "        \n",
    "        # 説明変数内のすべての次元に対して\n",
    "        for i in range(x.shape[1]):\n",
    "            feat = x[:, i]\n",
    "            for val in feat:\n",
    "                l, r = self.make_split(feat, val)\n",
    "                loss = self.make_loss(y[l], y[r], l, r)\n",
    "                if score > loss:\n",
    "                    score = loss\n",
    "                    left = l\n",
    "                    right = r\n",
    "                    self.feat_index = i\n",
    "                    self.feat_val = val\n",
    "        self.score = score # 最良の分割点スコア\n",
    "        return left, right\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        # 学習\n",
    "        # 必ずしも左右の葉に値が振り分けれるとは限らず、どちらか一方の葉のみにデータが集中する可能性がある\n",
    "        # ので、if文でデータの長さをチェックしてから学習を行う。\n",
    "        \n",
    "        self.leftModel = self.leafModel\n",
    "        self.rightModel = self.leafModel\n",
    "        \n",
    "        # データを左右の葉に振り分ける\n",
    "        left, right = self.split_tree(x, y)\n",
    "        \n",
    "        # 左右の葉を学習させる\n",
    "        if len(left) > 0:\n",
    "            self.leftModel.fit(x[left], y[right])\n",
    "        if len(right)> 0:\n",
    "            self.rightModel.fit(x[left], y[right])\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # 説明変数から分割した左右のインデックスを取得\n",
    "        feat = x[:, self.feat_index]\n",
    "        val = self.feat_val\n",
    "        l, r = self.make_split(feat, val)\n",
    "        \n",
    "        # 左右の葉を実行して結果を作成する\n",
    "        z = None\n",
    "        if len(l) > 0 and len(r) > 0:\n",
    "            left = self.leftModel.predict(x[l])\n",
    "            right = self.rightModel.predict(x[r])\n",
    "            z = np.zeros((x.shape[0], left.shape[1]))\n",
    "            z[l] = self.leftModel.predict(x)\n",
    "            z[r] = self.rightModel.predict(x)\n",
    "        elif len(l) > 0 :\n",
    "            z = self.leftModel.predict(x)\n",
    "        elif len(r) > 0 :\n",
    "            z = self.rightModel.predict(x)\n",
    "        return z\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '\\n'.join([\n",
    "            ' if feat[ %d ] <= %f then:' % (self.feat_index, self.feat_val),\n",
    "            ' %s' % (self.left, ),\n",
    "            ' else',\n",
    "            ' %s' % (self.right, )\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = support.get_base_args()\n",
    "ps.add_argument('--metric', '-m', default='', help='Metric function')\n",
    "ps.add_argument('--leaf', '-l', default='', help='Leaf class')\n",
    "args = ps.parse_args()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(args.input, sep=args.separator, header=args.header, index_col=args.indexcol)\n",
    "x = df[df.columns[:-1]].values\n",
    "\n",
    "if args.metrics == 'div':\n",
    "    mt = deviation\n",
    "elif args.metric = 'infgain':\n",
    "    mt = information_gain\n",
    "elif args.metric == 'gini':\n",
    "    mt = gini\n",
    "else:\n",
    "    mt = None\n",
    "    \n",
    "if args.leaf == 'zeror':\n",
    "    lf = ZeroRule\n",
    "elif args.leaf == 'linear':\n",
    "    lf = Linear\n",
    "else:\n",
    "    lf = None\n",
    "    \n",
    "if not args.regression:\n",
    "    y, clz = support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
